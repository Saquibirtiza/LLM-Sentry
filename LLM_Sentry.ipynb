{"cells":[{"cell_type":"markdown","metadata":{"id":"mDMqJyn7NXSe"},"source":["# **This Notebook contains code for utilizing the LLM-Sentry framework**"]},{"cell_type":"markdown","metadata":{"id":"yiRg_bMLWzQv"},"source":["To run this notebook successfully you need the following API keys\n","\n","\n","1.   [OPENAI](https://platform.openai.com/docs/quickstart/step-2-set-up-your-api-key) - name this key as OPENAI_API_KEY\n","2.   [HUGGINGFACE](https://www.nightfall.ai/ai-security-101/hugging-face-api-key) - name this key as HF_TOKEN\n","3.   [COHERE](https://cohere.com/pricing) - name this key as COHERE_API_KEY\n","\n"]},{"cell_type":"markdown","metadata":{"id":"af7o_sfLMywJ"},"source":["**Install dependencies**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dQL2Ig5uEek3"},"outputs":[],"source":["%%capture\n","!python -m pip install python-dotenv\n","!pip install openai\n","!pip install llama_index\n","!pip install llama-index-postprocessor-cohere-rerank\n","!python -m pip install cohere"]},{"cell_type":"markdown","metadata":{"id":"Qk1z3dzKNBxP"},"source":["## **Input Preparation**"]},{"cell_type":"markdown","metadata":{"id":"7d1nGCQLMR7B"},"source":["**Import Dependencies**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WNirQPp6ExMX","outputId":"8cea2d52-31d5-4a88-f215-af3a3ef899a9"},"outputs":[{"data":{"text/plain":["False"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["import os\n","from dotenv import load_dotenv\n","load_dotenv()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UWq7vbjFMQbE"},"outputs":[],"source":["import csv"]},{"cell_type":"markdown","metadata":{"id":"-bLuGZaTKXLD"},"source":["**Change Working Directory**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b4XevO_gGByu"},"outputs":[],"source":["os.chdir(\"/path/to/HarmfulKB\") # insert the path to where you have saved HarmfulKB on your device"]},{"cell_type":"markdown","metadata":{"id":"dVLEQWLUKa3D"},"source":["**Code to Prepare harmful files**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rFcQIk5pLp8T"},"outputs":[],"source":["# Define the harmful input file path\n","input_file_path = 'harmful.txt'\n","\n","# Read lines from the input text file\n","with open(input_file_path, 'r') as file:\n","    lines = file.readlines()\n","\n","# Create a directory to save all the new CSV files\n","os.mkdir('harmful')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WFrWtxiAH5LD"},"outputs":[],"source":["# Write each line to a new row in a new CSV file\n","for i, line in enumerate(lines):\n","    output_file_path = f'harmful/harmful_{i}.csv'\n","    with open(output_file_path, 'w', newline='') as csvfile:\n","      csv_writer = csv.writer(csvfile)\n","      csv_writer.writerow(['KB'])\n","      # Use strip() to remove any leading/trailing whitespace including newline characters\n","      csv_writer.writerow([line.strip()])\n","      csvfile.close()\n","\n","print(f'Lines from {input_file_path} have been written')"]},{"cell_type":"markdown","metadata":{"id":"sT4QBpZFKfvM"},"source":["**Code to Prepare harmless files**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AL4HXnsgMHNC"},"outputs":[],"source":["# Define the harmless input file path\n","input_file_path = 'harmless.txt'\n","\n","# Read lines from the input text file\n","with open(input_file_path, 'r') as file:\n","    lines = file.readlines()\n","\n","# Create a directory to save all the new CSV files\n","os.mkdir('harmless')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ibnxhRC0JfZf"},"outputs":[],"source":["# Write each line to a new row in a new CSV file\n","for i, line in enumerate(lines):\n","    output_file_path = f'harmless/harmless_{i}.csv'\n","    with open(output_file_path, 'w', newline='') as csvfile:\n","      csv_writer = csv.writer(csvfile)\n","      csv_writer.writerow(['KB'])\n","      # Use strip() to remove any leading/trailing whitespace including newline characters\n","      csv_writer.writerow([line.strip()])\n","      csvfile.close()\n","\n","print(f'Lines from {input_file_path} have been written')"]},{"cell_type":"markdown","metadata":{"id":"qiXSEFhgMtEJ"},"source":["**Preparing the Knowledge Base**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pG9AUGTJEsMi"},"outputs":[],"source":["# import OpenAI\n","from google.colab import userdata\n","import openai\n","\n","openai.api_key = userdata.get('OPENAI_API_KEY')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G5htiRSWE5CU"},"outputs":[],"source":["# generate vector database from csv files in knowledge base\n","from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n","\n","harmful_documents = SimpleDirectoryReader(input_dir=\"harmful\", required_exts=[\".csv\"]).load_data()\n","harmless_documents = SimpleDirectoryReader(input_dir=\"harmless\", required_exts=[\".csv\"]).load_data()\n","\n","documents = harmful_documents + harmless_documents\n","\n","index = VectorStoreIndex.from_documents(documents,show_progress=True)"]},{"cell_type":"markdown","metadata":{"id":"21mmz_nYNQGC"},"source":["## **The LLM-Sentry framework**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JqTsfM-ZG88Q"},"outputs":[],"source":["# import zero shot classifier\n","from transformers import pipeline\n","\n","classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cQECjlCuE7N0"},"outputs":[],"source":["# define query engine for RAG\n","# import Reranker module\n","from llama_index.core.indices.postprocessor import SimilarityPostprocessor\n","from llama_index.postprocessor.cohere_rerank import CohereRerank\n","from llama_index.llms.openai import OpenAI\n","\n","query_engine = index.as_query_engine()\n","\n","api_key = userdata.get(\"COHERE_API_KEY\")\n","cohere_rerank = CohereRerank(api_key=api_key, top_n=10)\n","postprocessor = SimilarityPostprocessor(similarity_cutoff = 0.80)\n","\n","query_engine = index.as_query_engine(\n","    similarity_top_k=4,\n","    node_postprocessors=[cohere_rerank],\n",")"]},{"cell_type":"markdown","metadata":{"id":"z9TK6ozQOCc0"},"source":["## **Code to test LLM-Sentry**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KKaigHppHC-0"},"outputs":[],"source":["import pandas as pd\n","\n","# provide a csv file containing your harmful/safe prompts\n","df = pd.read_csv('prompt.csv')\n","df.head()\n","sentences_list = df['Prompt in English'].tolist()\n","\n","# removing empty stings from a list of strings using one liner\n","filtered_list = [string for string in sentences_list if string]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MNpdBo_mHcbu"},"outputs":[],"source":["def iterate_nested_json_for_loop(json_obj, filepaths):\n","  for key, value in json_obj.items():\n","    if isinstance(value, dict):\n","      iterate_nested_json_for_loop(value, filepaths)\n","    else:\n","      if(key == 'file_path'):\n","        filepaths.append(str(key + value))\n","  return filepaths"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fh9B49A8Hewb"},"outputs":[],"source":["import re\n","splitted_sentences = []\n","\n","# split each sentence in input prompt\n","for prompt in sentences_list:\n","  sentence = prompt.split(\"\\n\")\n","  sentence = list(filter(None, sentence))\n","  sentence = [sent.replace('?', '.').split('.') for sent in sentence]\n","  sentence = [item for sublist in sentence for item in sublist]\n","  sentence = [string for string in sentence if string!=\"\"]\n","  print(sentence)\n","  splitted_sentences.append(sentence)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Be6e3SL9Hio9"},"outputs":[],"source":["from llama_index.core.response.pprint_utils import pprint_response\n","from openai import OpenAI\n","import time\n","\n","client = OpenAI(\n","    # This is the default and can be omitted\n","    api_key = userdata.get(\"OPENAI_API_KEY\")\n",")\n","\n","harmful_counter = 0\n","window_length = 2\n","\n","for sentences in splitted_sentences:\n","  flag = 0\n","  # check shift of intent using sliding window of size 2 (pairs)\n","  for i in range(len(sentences)-(window_length-1)):\n","    # concatenate each sentence in the window\n","    sequence_to_classify = \"\"\n","    for j in range(window_length):\n","      sequence_to_classify += sentences[i+j] + '. '\n","    candidate_labels = ['harmful', 'safe']\n","    # use zero shot classifier to quantify the overall intent of the sentences inside the window\n","    output = classifier(sequence_to_classify, candidate_labels)\n","    print(output)\n","    # if harmful score is above a predefined threshold of 0.5, set the prompt as harmful\n","    if output[\"labels\"][0] == \"harmful\" and output[\"scores\"][0] > 0.6:\n","      harmful_counter += 1\n","      flag = 1\n","      break\n","    elif output[\"labels\"][1] == \"harmful\" and output[\"scores\"][1] > 0.6:\n","      harmful_counter += 1\n","      flag = 1\n","      break\n","  # if prompt is marked as safe using zero shot classifier, further check each sentence using RAG method\n","  if flag == 0:\n","    for i in range(len(sentences)):\n","      majority_vote = 0\n","      #paraphrasing each sentence 4 times and extracting matches from vector database\n","      print(\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\", sentences[i])\n","      for j in range(5):\n","        rephrase_query = \"Rephrase the following: \" + sentences[i]\n","        paraphrased_sent = client.chat.completions.create(\n","          model=\"gpt-3.5-turbo\",\n","          messages=[\n","            {\"role\": \"user\", \"content\": rephrase_query}\n","          ]\n","        )\n","        paraphrased_sent = paraphrased_sent.choices[0].message.content\n","\n","        if paraphrased_sent != \"Empty Response\":\n","          # query_template2 = \"Is this harmful?: \" + paraphrased_sent\n","          query_template2 = paraphrased_sent\n","          print(\"...................................\", query_template2)\n","          # introduce delay because of cohere API which has limit of 10 calls/minute\n","          # time.sleep(6)\n","          response = query_engine.query(query_template2)\n","\n","          filepaths = []\n","          harmful_source = 0\n","          # counting how many of the extracted files were from the harmful knowledge base\n","          if(response.metadata != None):\n","            iterate_nested_json_for_loop(response.metadata, filepaths)\n","            # harmful_source = len([1 for paths in filepaths if \"harmful\" in paths])\n","            if \"harmful\" in filepaths[0]:\n","              harmful_source += 1\n","          print(\"harmful_source: \", harmful_source)\n","          # if any one of the retrieved documents are from harmful knowledge base we mark that paraphrased version as harmful\n","          if harmful_source > 0:\n","            majority_vote += 1\n","      # for each sentence if 3 out of the 5 paraphrased versions are harmful then we say the sentence is harmful\n","      if majority_vote > 2:\n","        harmful_counter += 1\n","        break\n","  print(\">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n","\n","\n","print(\"Detection Accuracy: \", harmful_counter/(len(splitted_sentences)))"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}